diff --git a/ambari-metrics/ambari-metrics-timelineservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/metrics/timeline/aggregators/TimelineMetricClusterAggregatorSecond.java b/ambari-metrics/ambari-metrics-timelineservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/metrics/timeline/aggregators/TimelineMetricClusterAggregatorSecond.java
index bdc0feb83f..6731eb3865 100644
--- a/ambari-metrics/ambari-metrics-timelineservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/metrics/timeline/aggregators/TimelineMetricClusterAggregatorSecond.java
+++ b/ambari-metrics/ambari-metrics-timelineservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/metrics/timeline/aggregators/TimelineMetricClusterAggregatorSecond.java
@@ -18,6 +18,7 @@
 package org.apache.hadoop.yarn.server.applicationhistoryservice.metrics.timeline.aggregators;
 
 
+import org.apache.commons.collections.MapUtils;
 import org.apache.commons.lang.StringUtils;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.metrics2.sink.timeline.PostProcessingUtil;
@@ -98,7 +99,7 @@ public class TimelineMetricClusterAggregatorSecond extends AbstractTimelineAggre
 
   @Override
   protected Condition prepareMetricQueryCondition(long startTime, long endTime) {
-    Condition condition = new DefaultCondition(null, null, null, null, startTime,
+    Condition condition = new DefaultCondition(null, null, null, null, startTime - serverTimeShiftAdjustment,
       endTime, null, null, true);
     condition.setNoLimit();
     condition.setFetchSize(resultsetFetchSize);
@@ -164,7 +165,7 @@ public class TimelineMetricClusterAggregatorSecond extends AbstractTimelineAggre
    * timeline.metrics.cluster.aggregator.minute.timeslice.interval
    * Normalize value by averaging them within the interval
    */
-  private void processAggregateClusterMetrics(Map<TimelineClusterMetric, MetricClusterAggregate> aggregateClusterMetrics,
+  protected void processAggregateClusterMetrics(Map<TimelineClusterMetric, MetricClusterAggregate> aggregateClusterMetrics,
                                               TimelineMetric metric, List<Long[]> timeSlices) {
     // Create time slices
     Map<TimelineClusterMetric, Double> clusterMetrics = sliceFromTimelineMetric(metric, timeSlices);
@@ -302,6 +303,17 @@ public class TimelineMetricClusterAggregatorSecond extends AbstractTimelineAggre
     } else {
       //For other metrics, ok to do only interpolation
 
+      Double defaultNextSeenValue = null;
+      if (MapUtils.isEmpty(timeSliceValueMap) && MapUtils.isNotEmpty(timelineMetric.getMetricValues())) {
+        //If no value was found within the start_time based slices, but the metric has value in the server_time range,
+        // use that.
+
+        LOG.debug("No value found within range for metric : " + timelineMetric.getMetricName());
+        Map.Entry<Long,Double> firstEntry  = timelineMetric.getMetricValues().firstEntry();
+        defaultNextSeenValue = firstEntry.getValue();
+        LOG.debug("Found a data point outside timeslice range: " + new Date(firstEntry.getKey()) + ": " + defaultNextSeenValue);
+      }
+
       for (int sliceNum = 0; sliceNum < timeSlices.size(); sliceNum++) {
         Long[] timeSlice = timeSlices.get(sliceNum);
 
@@ -324,6 +336,10 @@ public class TimelineMetricClusterAggregatorSecond extends AbstractTimelineAggre
             nextSeenValue = timeSliceValueMap.get(nextTimeSlice[1]);
           }
 
+          if (nextSeenValue == null) {
+            nextSeenValue = defaultNextSeenValue;
+          }
+
           Double interpolatedValue = PostProcessingUtil.interpolate(timeSlice[1],
             (prevTimeSlice != null ? prevTimeSlice[1] : null), lastSeenValue,
             (nextTimeSlice != null ? nextTimeSlice[1] : null), nextSeenValue);